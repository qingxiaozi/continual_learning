import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import os


class ResultVisualizer:
    """ç»“æœå¯è§†åŒ–ç±»"""

    def __init__(self, save_dir="./results"):
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)

        # è®¾ç½®ç»˜å›¾é£æ ¼
        plt.style.use("seaborn-v0_8")
        sns.set_palette("husl")

    def plot_training_loss(
        self, epoch_losses, val_losses=None, save_plot=True, plot_name="training_loss.png"
    ):
        """ç»˜åˆ¶è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŸå¤±æ›²çº¿"""
        plt.figure(figsize=(10, 6))

        # ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿
        epochs = range(1, len(epoch_losses) + 1)
        plt.plot(epochs, epoch_losses, "b-", linewidth=2, label="Training Loss", marker='o', markersize=4)

        # å¦‚æœæä¾›äº†éªŒè¯æŸå¤±ï¼Œç»˜åˆ¶éªŒè¯æŸå¤±æ›²çº¿
        if val_losses and len(val_losses) > 0:
            val_epochs = range(1, len(val_losses) + 1)
            plt.plot(val_epochs, val_losses, "r-", linewidth=2, label="Validation Loss", marker='s', markersize=4)

        # è®¾ç½®å›¾è¡¨å±æ€§
        title = "Training Loss vs Epochs" if not val_losses else "Training and Validation Loss"
        plt.title(title, fontsize=14, fontweight="bold")
        plt.xlabel("Epoch", fontsize=12)
        plt.ylabel("Loss", fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.legend(fontsize=10)

        # è®¾ç½®xè½´ä¸ºæ•´æ•°
        plt.xticks(epochs)

        # è‡ªåŠ¨è°ƒæ•´yè½´èŒƒå›´
        if len(epoch_losses) > 1:
            all_losses = epoch_losses
            if val_losses:
                all_losses = epoch_losses + val_losses[:len(epoch_losses)]  # åªå–ä¸è®­ç»ƒæŸå¤±å¯¹åº”é•¿åº¦çš„éªŒè¯æŸå¤±
            loss_range = max(all_losses) - min(all_losses)
            plt.ylim(
                min(all_losses) - 0.1 * loss_range,
                max(all_losses) + 0.1 * loss_range,
            )

        # ä¿å­˜æˆ–æ˜¾ç¤ºå›¾è¡¨
        if save_plot:
            plot_path = os.path.join(self.save_dir, plot_name)
            plt.savefig(plot_path, dpi=300, bbox_inches="tight")
            print(f"è®­ç»ƒæŸå¤±å›¾å·²ä¿å­˜è‡³: {plot_path}")

        plt.close()

        # # æ‰“å°è®­ç»ƒæ€»ç»“
        # if len(epoch_losses) > 1:
        #     self._print_training_summary(epoch_losses, val_losses)

    def _print_training_summary(self, train_losses, val_losses=None):
        """æ‰“å°è®­ç»ƒæ€»ç»“"""
        print("\nè®­ç»ƒæ€»ç»“:")
        print(f"æ€»è®­ç»ƒè½®æ¬¡: {len(train_losses)}")
        print(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_losses[-1]:.6f}")

        if train_losses[0] > 0:
            improvement = (train_losses[0] - train_losses[-1]) / train_losses[0] * 100
            print(f"è®­ç»ƒæŸå¤±æ”¹å–„: {improvement:.2f}%")

        if val_losses and len(val_losses) > 0:
            print(f"æœ€ç»ˆéªŒè¯æŸå¤±: {val_losses[-1]:.6f}")

            # æ‰¾å‡ºæœ€ä½³éªŒè¯æŸå¤±åŠå…¶å¯¹åº”çš„epoch
            best_val_epoch = val_losses.index(min(val_losses)) + 1
            best_val_loss = min(val_losses)
            print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f} (ç¬¬ {best_val_epoch} è½®)")

            if val_losses[0] > 0:
                val_improvement = (val_losses[0] - val_losses[-1]) / val_losses[0] * 100
                print(f"éªŒè¯æŸå¤±æ”¹å–„: {val_improvement:.2f}%")

    def calculate_metrics(
        self, performance_history, time_history=None, communication_costs=None
    ):
        """è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡"""
        metrics = {}

        if time_history is None:
            time_history = []
        if communication_costs is None:
            communication_costs = []

        # æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
        accuracies = [
            perf["accuracy"] for perf in performance_history if "accuracy" in perf
        ]
        losses = [perf["loss"] for perf in performance_history if "loss" in perf]

        if accuracies:
            metrics["final_accuracy"] = accuracies[-1]
            metrics["average_accuracy"] = np.mean(accuracies)
            metrics["min_accuracy"] = np.min(accuracies)
            metrics["max_accuracy"] = np.max(accuracies)

            # è®¡ç®—å‡†ç¡®ç‡ç¨³å®šæ€§
            metrics["accuracy_std"] = np.std(accuracies)
        else:
            metrics.update(
                {
                    "final_accuracy": 0,
                    "average_accuracy": 0,
                    "min_accuracy": 0,
                    "max_accuracy": 0,
                    "accuracy_std": 0,
                }
            )

        # é—å¿˜åº¦é‡
        if len(accuracies) > 1:
            forgetting = 0.0
            for i in range(1, len(accuracies)):
                forgetting += max(0, accuracies[i - 1] - accuracies[i])
            metrics["forgetting"] = forgetting / (len(accuracies) - 1)
        else:
            metrics["forgetting"] = 0.0

        # æŸå¤±æŒ‡æ ‡
        if losses:
            metrics["final_loss"] = losses[-1]
            metrics["average_loss"] = np.mean(losses)
            metrics["min_loss"] = np.min(losses)
            metrics["max_loss"] = np.max(losses)
        else:
            metrics.update(
                {"final_loss": 0, "average_loss": 0, "min_loss": 0, "max_loss": 0}
            )

        # ç³»ç»Ÿæ•ˆç‡æŒ‡æ ‡
        if communication_costs:
            metrics["total_communication_cost"] = np.sum(communication_costs)
            metrics["average_communication_cost"] = np.mean(communication_costs)
        else:
            metrics.update(
                {"total_communication_cost": 0, "average_communication_cost": 0}
            )

        if time_history:
            metrics["total_training_time"] = np.sum(time_history)
            metrics["average_time_per_session"] = np.mean(time_history)
            metrics["max_time_per_session"] = np.max(time_history)
        else:
            metrics.update(
                {
                    "total_training_time": 0,
                    "average_time_per_session": 0,
                    "max_time_per_session": 0,
                }
            )

        return metrics

    def plot_results(self, performance_history, algorithm_name, save_plot=True):
        """ç»˜åˆ¶ç»“æœå›¾è¡¨"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

        # å‡†ç¡®ç‡æ›²çº¿
        sessions = range(len(performance_history))
        accuracies = [perf.get("accuracy", 0) for perf in performance_history]
        losses = [perf.get("loss", 0) for perf in performance_history]

        ax1.plot(sessions, accuracies, "b-", linewidth=2, marker="o")
        ax1.set_xlabel("Training Session")
        ax1.set_ylabel("Accuracy")
        ax1.set_title(f"{algorithm_name} - Model Accuracy Over Time")
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(0, 1)  # å‡†ç¡®ç‡èŒƒå›´0-1

        # æŸå¤±æ›²çº¿
        ax2.plot(sessions, losses, "r-", linewidth=2, marker="s")
        ax2.set_xlabel("Training Session")
        ax2.set_ylabel("Loss")
        ax2.set_title(f"{algorithm_name} - Model Loss Over Time")
        ax2.grid(True, alpha=0.3)

        # ç½®ä¿¡åº¦åˆ†å¸ƒ
        confidences = []
        for perf in performance_history:
            if "confidence" in perf and perf["confidence"]:
                confidences.extend(perf["confidence"])

        if confidences:
            ax3.hist(confidences, bins=20, alpha=0.7, edgecolor="black", color="green")
            ax3.set_xlabel("Confidence")
            ax3.set_ylabel("Frequency")
            ax3.set_title(f"{algorithm_name} - Confidence Distribution")
            ax3.grid(True, alpha=0.3)
        else:
            ax3.text(
                0.5,
                0.5,
                "No confidence data",
                horizontalalignment="center",
                verticalalignment="center",
                transform=ax3.transAxes,
                fontsize=12,
            )
            ax3.set_title(f"{algorithm_name} - Confidence Distribution")

        # ç¼“å­˜ä½¿ç”¨æƒ…å†µ
        cache_sizes = []
        for perf in performance_history:
            if "cache_stats" in perf and perf["cache_stats"]:
                total_size = sum(
                    stats.get("total_size", 0) for stats in perf["cache_stats"].values()
                )
                cache_sizes.append(total_size)

        if cache_sizes:
            ax4.plot(
                range(len(cache_sizes)), cache_sizes, "g-", linewidth=2, marker="^"
            )
            ax4.set_xlabel("Training Session")
            ax4.set_ylabel("Total Cache Size")
            ax4.set_title(f"{algorithm_name} - Cache Usage Over Time")
            ax4.grid(True, alpha=0.3)
        else:
            ax4.text(
                0.5,
                0.5,
                "No cache data",
                horizontalalignment="center",
                verticalalignment="center",
                transform=ax4.transAxes,
                fontsize=12,
            )
            ax4.set_title(f"{algorithm_name} - Cache Usage Over Time")

        plt.tight_layout()

        if save_plot:
            plot_path = os.path.join(self.save_dir, f"{algorithm_name}_results.png")
            plt.savefig(plot_path, dpi=300, bbox_inches="tight")
            print(f"ç»“æœå›¾è¡¨å·²ä¿å­˜è‡³: {plot_path}")

        plt.show()
        return fig

    def plot_comparison(self, algorithms_results, save_plot=True):
        """æ¯”è¾ƒä¸åŒç®—æ³•çš„æ€§èƒ½"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()

        # å‡†ç¡®ç‡æ¯”è¾ƒ
        for algo_name, results in algorithms_results.items():
            accuracies = [
                perf.get("accuracy", 0) for perf in results["performance_history"]
            ]
            sessions = range(len(accuracies))
            axes[0].plot(sessions, accuracies, label=algo_name, linewidth=2)

        axes[0].set_xlabel("Training Session")
        axes[0].set_ylabel("Accuracy")
        axes[0].set_title("Accuracy Comparison")
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        # æŸå¤±æ¯”è¾ƒ
        for algo_name, results in algorithms_results.items():
            losses = [perf.get("loss", 0) for perf in results["performance_history"]]
            sessions = range(len(losses))
            axes[1].plot(sessions, losses, label=algo_name, linewidth=2)

        axes[1].set_xlabel("Training Session")
        axes[1].set_ylabel("Loss")
        axes[1].set_title("Loss Comparison")
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

        # é€šä¿¡æˆæœ¬æ¯”è¾ƒ
        algo_names = []
        comm_costs = []
        for algo_name, results in algorithms_results.items():
            if "communication_costs" in results:
                algo_names.append(algo_name)
                comm_costs.append(np.sum(results["communication_costs"]))

        if comm_costs:
            bars = axes[2].bar(algo_names, comm_costs, alpha=0.7)
            axes[2].set_xlabel("Algorithm")
            axes[2].set_ylabel("Total Communication Cost")
            axes[2].set_title("Communication Cost Comparison")
            # åœ¨æŸ±çŠ¶å›¾ä¸Šæ˜¾ç¤ºæ•°å€¼
            for bar, cost in zip(bars, comm_costs):
                axes[2].text(
                    bar.get_x() + bar.get_width() / 2,
                    bar.get_height(),
                    f"{cost:.0f}",
                    ha="center",
                    va="bottom",
                )

        # è®­ç»ƒæ—¶é—´æ¯”è¾ƒ
        algo_names = []
        train_times = []
        for algo_name, results in algorithms_results.items():
            if "time_history" in results and results["time_history"]:
                algo_names.append(algo_name)
                train_times.append(np.sum(results["time_history"]))

        if train_times:
            bars = axes[3].bar(algo_names, train_times, alpha=0.7, color="orange")
            axes[3].set_xlabel("Algorithm")
            axes[3].set_ylabel("Total Training Time (s)")
            axes[3].set_title("Training Time Comparison")
            # åœ¨æŸ±çŠ¶å›¾ä¸Šæ˜¾ç¤ºæ•°å€¼
            for bar, time_val in zip(bars, train_times):
                axes[3].text(
                    bar.get_x() + bar.get_width() / 2,
                    bar.get_height(),
                    f"{time_val:.1f}s",
                    ha="center",
                    va="bottom",
                )

        plt.tight_layout()

        if save_plot:
            plot_path = os.path.join(self.save_dir, "algorithm_comparison.png")
            plt.savefig(plot_path, dpi=300, bbox_inches="tight")
            print(f"ç®—æ³•æ¯”è¾ƒå›¾å·²ä¿å­˜è‡³: {plot_path}")

        plt.show()
        return fig

    def print_detailed_metrics(self, metrics, algorithm_name):
        """æ‰“å°è¯¦ç»†çš„æŒ‡æ ‡æŠ¥å‘Š"""
        print(f"\n{'='*50}")
        print(f"{algorithm_name} è¯¦ç»†æŒ‡æ ‡æŠ¥å‘Š")
        print(f"{'='*50}")

        print(f"\nğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ ‡:")
        print(f"  æœ€ç»ˆå‡†ç¡®ç‡: {metrics.get('final_accuracy', 0):.4f}")
        print(f"  å¹³å‡å‡†ç¡®ç‡: {metrics.get('average_accuracy', 0):.4f}")
        print(
            f"  å‡†ç¡®ç‡èŒƒå›´: {metrics.get('min_accuracy', 0):.4f} - {metrics.get('max_accuracy', 0):.4f}"
        )
        print(f"  å‡†ç¡®ç‡æ ‡å‡†å·®: {metrics.get('accuracy_std', 0):.4f}")
        print(f"  é—å¿˜åº¦é‡: {metrics.get('forgetting', 0):.4f}")

        print(f"\nâš¡ ç³»ç»Ÿæ•ˆç‡æŒ‡æ ‡:")
        print(f"  æ€»é€šä¿¡æˆæœ¬: {metrics.get('total_communication_cost', 0):.0f}")
        print(f"  å¹³å‡é€šä¿¡æˆæœ¬: {metrics.get('average_communication_cost', 0):.2f}")
        print(f"  æ€»è®­ç»ƒæ—¶é—´: {metrics.get('total_training_time', 0):.2f}s")
        print(f"  å¹³å‡æ¯è½®æ—¶é—´: {metrics.get('average_time_per_session', 0):.2f}s")

        print(f"\nğŸ“ˆ æŸå¤±æŒ‡æ ‡:")
        print(f"  æœ€ç»ˆæŸå¤±: {metrics.get('final_loss', 0):.4f}")
        print(f"  å¹³å‡æŸå¤±: {metrics.get('average_loss', 0):.4f}")
        print(
            f"  æŸå¤±èŒƒå›´: {metrics.get('min_loss', 0):.4f} - {metrics.get('max_loss', 0):.4f}"
        )

    def plot_data_heterogeneity(
        self, data_simulator, session, save_plot=True, plot_name=None
    ):
        """
        ç»˜åˆ¶æ•°æ®å¼‚è´¨æ€§ç¤ºæ„å›¾

        å‚æ•°:
            data_simulator: DomainIncrementalDataSimulatorå®ä¾‹
            session: å½“å‰ä¼šè¯ID
            save_plot: æ˜¯å¦ä¿å­˜å›¾ç‰‡
            plot_name: å›¾ç‰‡åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        """
        if plot_name is None:
            plot_name = f"data_heterogeneity_session_{session}.png"

        # è·å–å½“å‰åŸŸçš„ä¿¡æ¯
        current_domain = data_simulator.get_current_domain()
        domain_key = f"{data_simulator.current_dataset}_{current_domain}"

        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®åˆ†é…
        if domain_key not in data_simulator.vehicle_data_assignments:
            print(f"è­¦å‘Š: åŸŸ {domain_key} æ²¡æœ‰æ•°æ®åˆ†é…ä¿¡æ¯")
            return

        # è·å–ç±»åˆ«ä¿¡æ¯
        num_classes = data_simulator.dataset_info[data_simulator.current_dataset][
            "num_classes"
        ]
        class_labels = [f"Class {i}" for i in range(num_classes)]

        # è·å–è½¦è¾†åˆ†é…æ•°æ®
        vehicle_assignments = data_simulator.vehicle_data_assignments[domain_key]
        train_dataset = data_simulator.train_data_cache[domain_key]

        # ç»Ÿè®¡æ¯ä¸ªè½¦è¾†æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡
        vehicle_class_counts = {}

        for vehicle_id, indices in vehicle_assignments.items():
            class_counts = {i: 0 for i in range(num_classes)}

            for idx in indices:
                # è·å–æ ·æœ¬çš„æ ‡ç­¾
                _, label = train_dataset[idx]
                class_counts[label] += 1

            vehicle_class_counts[vehicle_id] = class_counts

        # å‡†å¤‡ç»˜å›¾æ•°æ®
        vehicle_ids = []
        class_ids = []
        sample_counts = []

        for vehicle_id in range(data_simulator.num_vehicles):
            if vehicle_id in vehicle_class_counts:
                for class_id in range(num_classes):
                    count = vehicle_class_counts[vehicle_id][class_id]
                    if count > 0:  # åªç»˜åˆ¶æœ‰æ ·æœ¬çš„ç±»åˆ«
                        vehicle_ids.append(vehicle_id)
                        class_ids.append(class_id)
                        sample_counts.append(count)

        if not sample_counts:
            print("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°å¯ç»˜åˆ¶çš„æ•°æ®")
            return

        # åˆ›å»ºå›¾å½¢
        plt.figure(figsize=(12, 8))

        # åˆ›å»ºæ•£ç‚¹å›¾ï¼Œç‚¹çš„å¤§å°è¡¨ç¤ºæ ·æœ¬æ•°é‡
        scatter = plt.scatter(
            vehicle_ids,
            class_ids,
            s=[
                min(100 + count * 2, 500) for count in sample_counts
            ],  # åŠ¨æ€è°ƒæ•´ç‚¹çš„å¤§å°
            c=sample_counts,
            cmap="viridis",
            alpha=0.7,
            edgecolors="black",
            linewidth=0.5,
        )

        # è®¾ç½®å›¾è¡¨å±æ€§
        plt.title(
            f"Data Heterogeneity - Session {session}\n(Domain: {current_domain}, Dataset: {data_simulator.current_dataset})",
            fontsize=14,
            fontweight="bold",
            pad=20,
        )
        plt.xlabel("Vehicle ID", fontsize=12)
        plt.ylabel("Class Label", fontsize=12)

        # è®¾ç½®åæ ‡è½´
        plt.xticks(range(data_simulator.num_vehicles))
        plt.yticks(range(num_classes), class_labels)
        plt.grid(True, alpha=0.3, linestyle="--")

        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(scatter, shrink=0.8)
        cbar.set_label("Number of Samples", fontsize=10)

        # æ·»åŠ æ ·æœ¬æ•°é‡æ ‡æ³¨ï¼ˆåªæ ‡æ³¨è¾ƒå¤§çš„ç‚¹ï¼‰
        for i, (vehicle_id, class_id, count) in enumerate(
            zip(vehicle_ids, class_ids, sample_counts)
        ):
            if count > max(sample_counts) * 0.3:  # åªæ ‡æ³¨è¾ƒå¤§çš„æ ·æœ¬ç‚¹
                plt.annotate(
                    str(count),
                    (vehicle_id, class_id),
                    xytext=(5, 5),
                    textcoords="offset points",
                    fontsize=8,
                    ha="left",
                    va="bottom",
                )

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜æˆ–æ˜¾ç¤ºå›¾è¡¨
        if save_plot:
            plot_path = os.path.join(self.save_dir, plot_name)
            plt.savefig(plot_path, dpi=300, bbox_inches="tight")
            print(f"æ•°æ®å¼‚è´¨æ€§å›¾å·²ä¿å­˜è‡³: {plot_path}")

        plt.close()

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        # self._print_heterogeneity_statistics(vehicle_class_counts, current_domain, session)

    def _print_heterogeneity_statistics(self, vehicle_class_counts, domain, session):
        """æ‰“å°æ•°æ®å¼‚è´¨æ€§ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n=== Session {session} - {domain} æ•°æ®å¼‚è´¨æ€§ç»Ÿè®¡ ===")

        total_samples = 0
        class_coverage = {}  # æ¯ä¸ªç±»åˆ«è¢«å¤šå°‘è½¦è¾†è¦†ç›–

        for vehicle_id, class_counts in vehicle_class_counts.items():
            vehicle_total = sum(class_counts.values())
            total_samples += vehicle_total

            # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„è¦†ç›–æƒ…å†µ
            for class_id, count in class_counts.items():
                if count > 0:
                    class_coverage[class_id] = class_coverage.get(class_id, 0) + 1

            print(
                f"è½¦è¾† {vehicle_id}: {vehicle_total} ä¸ªæ ·æœ¬, è¦†ç›– {sum(1 for c in class_counts.values() if c > 0)} ä¸ªç±»åˆ«"
            )

        # è®¡ç®—å¼‚è´¨æ€§æŒ‡æ ‡
        vehicle_totals = [
            sum(counts.values()) for counts in vehicle_class_counts.values()
        ]
        heterogeneity_std = np.std(vehicle_totals) if vehicle_totals else 0

        print(f"\næ€»ä½“ç»Ÿè®¡:")
        print(f"æ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"å¹³å‡æ¯è½¦æ ·æœ¬æ•°: {np.mean(vehicle_totals):.1f}")
        print(f"æ ·æœ¬æ•°æ ‡å‡†å·®: {heterogeneity_std:.1f} (å¼‚è´¨æ€§æŒ‡æ ‡)")
        print(
            f"ç±»åˆ«è¦†ç›–æƒ…å†µ: å¹³å‡æ¯ä¸ªç±»åˆ«è¢« {np.mean(list(class_coverage.values())):.1f} è¾†è½¦è¦†ç›–"
        )
        print("====================================\n")

    def plot_continual_learning_metrics(self, results, save_path=None, show_plot=True):
        """
        ç»˜åˆ¶è¿ç»­å­¦ä¹ æŒ‡æ ‡éšåŸŸåˆ‡æ¢çš„å˜åŒ–è¶‹åŠ¿

        å‚æ•°:
            results: åŒ…å«è®°å½•ç»“æœçš„å­—å…¸
            save_path: ä¿å­˜å›¾ç‰‡çš„è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            show_plot: æ˜¯å¦æ˜¾ç¤ºå›¾ç‰‡
        """
        if "continual_learning_metrics" not in results or not results["continual_learning_metrics"]:
            print("æ²¡æœ‰æ‰¾åˆ°è¿ç»­å­¦ä¹ æŒ‡æ ‡æ•°æ®")
            return

        metrics_data = results["continual_learning_metrics"]

        # æå–æ•°æ®
        sessions = [m["session"] for m in metrics_data]
        tasks = [m["task"] for m in metrics_data]
        domains = [m["domain"] for m in metrics_data]

        # å››ä¸ªæ ¸å¿ƒæŒ‡æ ‡
        aa_values = [m["AA"] for m in metrics_data]
        aia_values = [m["AIA"] for m in metrics_data]
        fm_values = [m["FM"] for m in metrics_data]
        bwt_values = [m["BWT"] for m in metrics_data]

        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(3, 2, figsize=(14, 12))
        fig.suptitle('Continual Learning Metrics Evolution', fontsize=16, fontweight='bold')

        # è®¾ç½®ç™½è‰²èƒŒæ™¯
        fig.patch.set_facecolor('white')
        for ax in axes.flat:
            ax.set_facecolor('white')

        # 1. å¹³å‡å‡†ç¡®ç‡ (AA) è¶‹åŠ¿
        ax1 = axes[0, 0]
        ax1.plot(sessions, aa_values, 'b-', linewidth=2, marker='o', markersize=4)
        ax1.set_xlabel('Session', fontsize=10)
        ax1.set_ylabel('AA (Average Accuracy)', fontsize=10)
        ax1.set_title('Average Accuracy Trend', fontsize=12, fontweight='bold')
        ax1.grid(True, alpha=0.3, linestyle='--')
        ax1.set_ylim(0, 1.05)

        # æ ‡è®°åŸŸåˆ‡æ¢ç‚¹
        self._mark_domain_changes(ax1, sessions, tasks, domains)

        # 2. å¹³å‡å¢é‡å‡†ç¡®ç‡ (AIA) è¶‹åŠ¿
        ax2 = axes[0, 1]
        ax2.plot(sessions, aia_values, 'g-', linewidth=2, marker='s', markersize=4)
        ax2.set_xlabel('Session', fontsize=10)
        ax2.set_ylabel('AIA (Average Incremental Accuracy)', fontsize=10)
        ax2.set_title('Average Incremental Accuracy Trend', fontsize=12, fontweight='bold')
        ax2.grid(True, alpha=0.3, linestyle='--')
        ax2.set_ylim(0, 1.05)

        # 3. é—å¿˜åº¦é‡ (FM) è¶‹åŠ¿
        ax3 = axes[1, 0]
        ax3.plot(sessions, fm_values, 'r-', linewidth=2, marker='^', markersize=4)
        ax3.set_xlabel('Session', fontsize=10)
        ax3.set_ylabel('FM (Forgetting Measure)', fontsize=10)
        ax3.set_title('Forgetting Measure Trend (lower is better)', fontsize=12, fontweight='bold')
        ax3.grid(True, alpha=0.3, linestyle='--')
        ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.5)

        # 4. åå‘è¿ç§» (BWT) è¶‹åŠ¿
        ax4 = axes[1, 1]
        ax4.plot(sessions, bwt_values, 'purple', linewidth=2, marker='d', markersize=4)
        ax4.set_xlabel('Session', fontsize=10)
        ax4.set_ylabel('BWT (Backward Transfer)', fontsize=10)
        ax4.set_title('Backward Transfer Trend (positive is good)', fontsize=12, fontweight='bold')
        ax4.grid(True, alpha=0.3, linestyle='--')
        ax4.axhline(y=0, color='gray', linestyle='--', alpha=0.5)

        # 5. ä»»åŠ¡/åŸŸåˆ‡æ¢ä¿¡æ¯
        ax5 = axes[2, 0]
        self._plot_task_domain_info(ax5, sessions, tasks, domains)

        # 6. æŒ‡æ ‡å¯¹æ¯”å›¾
        ax6 = axes[2, 1]
        self._plot_metrics_comparison(ax6, sessions, aa_values, aia_values, fm_values, bwt_values)

        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
            print(f"å›¾ç‰‡å·²ä¿å­˜åˆ°: {save_path}")

        # æ˜¾ç¤ºå›¾ç‰‡
        if show_plot:
            plt.show()
        else:
            plt.close()

    def _mark_domain_changes(self, ax, sessions, tasks, domains):
        """åœ¨å›¾ä¸Šæ ‡è®°åŸŸåˆ‡æ¢ç‚¹"""
        current_domain = None
        change_points = []

        for i, domain in enumerate(domains):
            if domain != current_domain:
                change_points.append((sessions[i], domain))
                current_domain = domain

        for session, domain in change_points:
            ax.axvline(x=session, color='orange', linestyle=':', alpha=0.5, linewidth=1)
            ax.text(session, ax.get_ylim()[1]*0.95, domain,
                   rotation=90, fontsize=8, alpha=0.7,
                   verticalalignment='top')

    def _plot_task_domain_info(self, ax, sessions, tasks, domains):
        """ç»˜åˆ¶ä»»åŠ¡å’ŒåŸŸä¿¡æ¯"""
        ax.set_title('Task/Domain Progression', fontsize=12, fontweight='bold')
        ax.set_xlabel('Session', fontsize=10)

        # åˆ›å»ºé¢œè‰²æ˜ å°„
        unique_domains = list(dict.fromkeys(domains))  # ä¿æŒé¡ºåºå»é‡
        colors = plt.cm.Set3(np.linspace(0, 1, len(unique_domains)))
        domain_to_color = {domain: colors[i] for i, domain in enumerate(unique_domains)}

        # ç»˜åˆ¶ä»»åŠ¡æ¡å½¢å›¾
        for i, (session, task, domain) in enumerate(zip(sessions, tasks, domains)):
            color = domain_to_color.get(domain, 'gray')
            ax.barh(task, 1, left=session-0.5, height=0.8,
                   color=color, alpha=0.7, edgecolor='black', linewidth=0.5)
            if i == 0 or domains[i] != domains[i-1]:
                ax.text(session, task, f"{domain}\n(T{task})",
                       fontsize=7, ha='center', va='center')

        ax.set_yticks(sorted(set(tasks)))
        ax.set_ylabel('Task Number', fontsize=10)
        ax.grid(True, alpha=0.3, axis='x')

    def _plot_metrics_comparison(self, ax, sessions, aa, aia, fm, bwt):
        """ç»˜åˆ¶æŒ‡æ ‡å¯¹æ¯”å›¾ï¼ˆå½’ä¸€åŒ–åï¼‰"""
        ax.set_title('Normalized Metrics Comparison', fontsize=12, fontweight='bold')
        ax.set_xlabel('Session', fontsize=10)
        ax.set_ylabel('Normalized Value', fontsize=10)

        # å½’ä¸€åŒ–å¤„ç†ï¼ˆFMå’ŒBWTéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
        aa_norm = aa  # AAå·²ç»åœ¨0-1èŒƒå›´å†…
        aia_norm = aia  # AIAä¹Ÿåœ¨0-1èŒƒå›´å†…

        # FMå½’ä¸€åŒ–åˆ°0-1ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        if max(fm) > 0:
            fm_norm = [1 - f/max(fm) for f in fm]  # åè½¬ï¼Œè¶Šé«˜è¶Šå¥½
        else:
            fm_norm = [0] * len(fm)

        # BWTå½’ä¸€åŒ–åˆ°0-1ï¼ˆå¤„ç†è´Ÿå€¼ï¼‰
        bwt_min = min(bwt)
        bwt_max = max(bwt)
        if bwt_max > bwt_min:
            bwt_norm = [(b - bwt_min) / (bwt_max - bwt_min) for b in bwt]
        else:
            bwt_norm = [0.5] * len(bwt)

        # ç»˜åˆ¶å½’ä¸€åŒ–åçš„æŒ‡æ ‡
        ax.plot(sessions, aa_norm, 'b-', label='AA', linewidth=2)
        ax.plot(sessions, aia_norm, 'g--', label='AIA', linewidth=2)
        ax.plot(sessions, fm_norm, 'r-.', label='FM (inverted)', linewidth=2)
        ax.plot(sessions, bwt_norm, 'purple:', label='BWT (normalized)', linewidth=2)

        ax.legend(fontsize=9)
        ax.grid(True, alpha=0.3, linestyle='--')
        ax.set_ylim(-0.1, 1.1)